//
//  File.swift
//  CoreRecorder
//
//  Created by lixindong on 2025/6/6.
//

import Foundation
import AVFoundation
import Combine

public class CRRecorder: @unchecked Sendable {
    
    var outputDirectory: URL
    var schemes: [SchemeItem]
    var captureSessions: [String: AVCaptureSession] = [:]
    var captureDelegates: [String: CaptureRecordingDelegate] = [:]
    /// å½“å‰å±å¹•å½•åˆ¶åç«¯ï¼ˆScreenCaptureKit æˆ– AVFoundationï¼‰ï¼Œå•æ¬¡å½•åˆ¶ä»…ä½¿ç”¨ä¸€ä¸ªå®ä¾‹ã€‚
    var screenCaptureSessions: ScreenRecorderBackend?
    
    var appleDeviceCaptures: [String: CRAppleDeviceRecording] = [:]
    var cameraCaptures: [String: CRCameraRecording] = [:]
    var microphoneCaptures: [String: CRMicrophoneRecording] = [:]
    // å¯åˆ‡æ¢çš„éº¦å…‹é£å½•åˆ¶åç«¯ï¼ˆé»˜è®¤æ²¿ç”¨æ—§æ–¹æ¡ˆï¼‰
//    public var microphoneBackend: CRMicrophoneRecording.Backend = .fileOutput
    
    nonisolated(unsafe)
    public var onInterupt: (Error) -> Void = {_ in}
    
    var resultSubject: PassthroughSubject<Result, Error> = .init()
    public var audioLevelSubject: PassthroughSubject<Float, Never> = .init()
    
    // Idempotent stopping guardsï¼ˆæ ‡è®°ä½æ–¹æ¡ˆï¼‰
    private var isStoppingAll: Bool = false
    private var stopAllCachedResult: Result? = nil

    /// å±å¹•å½•åˆ¶åç«¯ç±»å‹ã€‚
    public enum ScreenBackend: String, Sendable {
        case screenCaptureKit
        case avFoundation
    }

    public init(_ schemes: [SchemeItem], outputDirectory: URL) {
        self.schemes = schemes
        self.outputDirectory = outputDirectory
        print("[CRRecorder] åˆå§‹åŒ–å½•åˆ¶å™¨ï¼Œè¾“å‡ºç›®å½•: \(outputDirectory.path), å½•åˆ¶æ–¹æ¡ˆæ•°é‡: \(schemes.count)")
    }
    
    public func prepare(_ schemes: [SchemeItem]) async throws {
        print("[CRRecorder] å¼€å§‹å‡†å¤‡å½•åˆ¶æ–¹æ¡ˆï¼Œå…± \(schemes.count) ä¸ª")
        self.schemes = schemes
        
        for scheme in schemes {
            print("[CRRecorder] å‡†å¤‡å½•åˆ¶æ–¹æ¡ˆ: \(scheme.id)")
            switch scheme {
            case .display(
                let displayId,
                let area,
                let fps,
                let showsCursor,
                let hdr,
                let useHEVC,
                let captureSystemAudio,
                let queueDepth,
                let targetBitRate,
                let filename,
                let backend,
                let excludedWindowTitles
            ):
                print("[CRRecorder] å‡†å¤‡å±å¹•å½•åˆ¶ - æ˜¾ç¤ºå™¨ID: \(displayId), æ–‡ä»¶å: \(filename), HDR: \(hdr), ç³»ç»ŸéŸ³é¢‘: \(captureSystemAudio)")
                screenCaptureSessions = makeScreenBackend(
                    backend: backend,
                    filename: filename,
                    fps: fps,
                    queueDepth: queueDepth,
                    targetBitRate: targetBitRate,
                    showsCursor: showsCursor,
                    useHEVC: useHEVC
                )
            case .window(
                displayId: let displayId,
                windowID: let windowID,
                let fps,
                let showsCursor,
                hdr: let hdr,
                captureSystemAudio: let captureSystemAudio,
                filename: let filename,
                let backend,
                let queueDepth,
                let targetBitRate
            ):
                print("[CRRecorder] å‡†å¤‡çª—å£å½•åˆ¶ - æ˜¾ç¤ºå™¨ID: \(displayId), çª—å£ID: \(windowID), æ–‡ä»¶å: \(filename)")
                screenCaptureSessions = makeScreenBackend(
                    backend: backend,
                    filename: filename,
                    fps: fps,
                    queueDepth: queueDepth,
                    targetBitRate: targetBitRate,
                    showsCursor: showsCursor,
                    useHEVC: false
                )
            case .camera(cameraID: let cameraID, filename: let filename, let cameraOptions):
                print("[CRRecorder] å‡†å¤‡æ‘„åƒå¤´å½•åˆ¶ - æ‘„åƒå¤´ID: \(cameraID), æ–‡ä»¶å: \(filename)")
//                prepareCameraSession(cameraID: cameraID, filename: filename)
                let cameraRecording = CRCameraRecording()
                cameraRecording.options = cameraOptions
                cameraRecording.onError = { err in
                    NSLog("ğŸ“¹ [CR_RECORDER_CAMERA_ERROR] CRRecorder æ¥æ”¶åˆ°æ‘„åƒå¤´é”™è¯¯: %@", err.localizedDescription)
                    self.onInterupt(err)
                }
                cameraRecording.onComplete = { [unowned self] url in}
                try await cameraRecording.prepare(cameraId: cameraID)
                
                cameraCaptures[cameraID] = cameraRecording
                break
            case .microphone(microphoneID: let microphoneID, filename: let filename, let microphoneOptions):
                print("[CRRecorder] å‡†å¤‡éº¦å…‹é£å½•åˆ¶ - éº¦å…‹é£ID: \(microphoneID), æ–‡ä»¶å: \(filename)")
//                prepareMicrophoneSession(microphoneID: microphoneID, filename: filename)
                let microphoneRecording = CRMicrophoneRecording()
                microphoneRecording.audioLevelHandler = { [weak self] level, peak in
                    self?.audioLevelSubject.send(level)
                }
                microphoneRecording.onError = { [weak self] err in
                    NSLog("ğŸ¤ [CR_RECORDER_MIC_ERROR] CRRecorder æ¥æ”¶åˆ°éº¦å…‹é£é”™è¯¯: %@", err.localizedDescription)
                    self?.onInterupt(err)
                }
                // Apply per-run mic options
                microphoneRecording.processingOptions = microphoneOptions
                try await microphoneRecording.prepare(microphoneID: microphoneID)
                microphoneCaptures[microphoneID] = microphoneRecording
                break
            case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename, let cameraOptions):
                print("[CRRecorder] å‡†å¤‡è‹¹æœè®¾å¤‡å½•åˆ¶ - è®¾å¤‡ID: \(appleDeviceID), æ–‡ä»¶å: \(filename)")
                let appleDeviceRecording = CRAppleDeviceRecording()
                appleDeviceRecording.options = cameraOptions
                appleDeviceRecording.onError = { err in
                    NSLog("ğŸ“± [CR_RECORDER_APPLE_DEVICE_ERROR] CRRecorder æ¥æ”¶åˆ° Apple è®¾å¤‡é”™è¯¯: %@", err.localizedDescription)
                    self.onInterupt(err)
                }
                try await appleDeviceRecording.prepare(deviceId: appleDeviceID)
                appleDeviceCaptures[appleDeviceID] = appleDeviceRecording
                break
            }
        }
        print("[CRRecorder] å½•åˆ¶æ–¹æ¡ˆå‡†å¤‡å®Œæˆ")
    }
    
    public func startRecording() async throws {
        // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if !FileManager.default.fileExists(atPath: outputDirectory.path) {
            print("[CRRecorder] åˆ›å»ºè¾“å‡ºç›®å½•: \(outputDirectory.path)")
            try FileManager.default.createDirectory(at: outputDirectory, withIntermediateDirectories: true)
        }

        // æŒ‰è®¾å¤‡ç±»å‹åˆ†ç»„
        let auxiliarySchemes = schemes.filter { scheme in
            switch scheme {
            case .camera, .microphone:
                return true // è¾…åŠ©è®¾å¤‡
            default:
                return false
            }
        }
        
        let primarySchemes = schemes.filter { scheme in
            switch scheme {
            case .display, .window, .appleDevice:
                return true // ä¸»è®¾å¤‡ï¼ˆå±å¹•/çª—å£å½•åˆ¶ï¼‰
            default:
                return false
            }
        }
        
        try await withThrowingTaskGroup { group  in
            for scheme in auxiliarySchemes {
                group.addTask {
                    try await self.startRecord(scheme: scheme)
                }
            }
            try await group.waitForAll()
        }
        print("[CRRecorder] æ‰€æœ‰ auxiliary å½•åˆ¶ä»»åŠ¡å…¨éƒ¨å¼€å§‹")
        try await withThrowingTaskGroup { group in
            for scheme in primarySchemes {
                group.addTask {
                    try await self.startRecord(scheme: scheme)
                }
            }
            try await group.waitForAll()
        }
        
        print("[CRRecorder] æ‰€æœ‰å½•åˆ¶ä»»åŠ¡å…¨éƒ¨å¼€å§‹")
        packLastResult()
    }
    
    // æ•´ç† result
    public func packLastResult() -> Result? {
        var fileAssets: [BundleInfo.FileAsset] = []
        for scheme in schemes {
            switch scheme {
            case .display:
                let assets = screenCaptureSessions?.packLastResult() ?? []
                fileAssets.append(contentsOf: assets)
            case .window:
                let assets = screenCaptureSessions?.packLastResult() ?? []
                fileAssets.append(contentsOf: assets)
            case .camera(cameraID: let cameraID, filename: _, cameraOptions: _):
                if let cameraCapture = cameraCaptures[cameraID] {
                    let fileAsset = cameraCapture.packLastResult()
                    fileAssets.append(contentsOf: fileAsset)
                }
            case .microphone(microphoneID: let microphoneID, filename: _, microphoneOptions: _):
                if let avCapture = microphoneCaptures[microphoneID] {
                    let fileAsset = avCapture.packLastResult()
                    fileAssets.append(contentsOf: fileAsset)
                }
            case .appleDevice(appleDeviceID: let appleDeviceID, filename: _, cameraOptions: _):
                if let avCapture = appleDeviceCaptures[appleDeviceID] {
                    let fileAsset = avCapture.packLastResult()
                    fileAssets.append(contentsOf: fileAsset)
                }
            }
        }
        
        let result = Result(bundleURL: outputDirectory, bundleInfo: BundleInfo(duration: 0, files: fileAssets, version: 0))
        print("[CRRecorder] æ‰€æœ‰å½•åˆ¶ä»»åŠ¡å®Œæˆï¼Œæ€»æ–‡ä»¶æ•°é‡: \(fileAssets.count)")
        
        resultSubject.send(result)
        
        return result
    }
    
    func startRecord(scheme: SchemeItem) async throws {
        switch scheme {
        case .display(
            displayID: let displayID,
            area: let area,
            fps: _,
            showsCursor: let showsCursor,
            hdr: let hdr,
            useHEVC: _,
            captureSystemAudio: let captureSystemAudio,
            queueDepth: _,
            targetBitRate: _,
            filename: _,
            backend: _,
            excludedWindowTitles: let excludedWindowTitles
        ):
            // åœ¨ prepare é˜¶æ®µå·²æ ¹æ® backend åˆå§‹åŒ–å¥½ screenCaptureSessionsï¼Œè¿™é‡Œç›´æ¥å¯åŠ¨ã€‚
            _ = try await screenCaptureSessions?.startScreenCapture(
                displayID: displayID,
                cropRect: area,
                hdr: hdr,
                showsCursor: showsCursor,
                includeAudio: captureSystemAudio,
                excludedWindowTitles: excludedWindowTitles
            )
        case .window(
            displayId: let displayId,
            windowID: let windowID,
            fps: let fps,
            showsCursor: let showsCursor,
            hdr: let hdr,
            captureSystemAudio: let captureSystemAudio,
            filename: _,
            backend: _,
            queueDepth: _,
            targetBitRate: _
        ):
            _ = try await screenCaptureSessions?.startWindowCapture(
                windowID: windowID,
                displayID: displayId,
                hdr: hdr,
                showsCursor: showsCursor,
                includeAudio: captureSystemAudio,
                frameRate: fps,
                h265: false
            )
        case .camera(cameraID: let cameraID, filename: let filename, cameraOptions: _):
            if let cameraCapture = cameraCaptures[cameraID] {
                let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .movie).appendingPathExtension("mov")
                try await cameraCapture.start(fileURL: fileURL)
            }
        case .microphone(microphoneID: let microphoneID, filename: let filename, microphoneOptions: _):
            if let avCapture = microphoneCaptures[microphoneID] {
                let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Audio)
                try await avCapture.start(fileURL: fileURL)
            }
        case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename, cameraOptions: _):
            if let avCapture = appleDeviceCaptures[appleDeviceID] {
                let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .movie).appendingPathExtension("mov")
                try await avCapture.start(fileURL: fileURL)
            }
        }
    }
    
    func startRecordingWithResult() async throws -> Result {
        print("[CRRecorder] å¼€å§‹å½•åˆ¶")
        return try await withThrowingTaskGroup { group in
            // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            if !FileManager.default.fileExists(atPath: outputDirectory.path) {
                print("[CRRecorder] åˆ›å»ºè¾“å‡ºç›®å½•: \(outputDirectory.path)")
                try FileManager.default.createDirectory(at: outputDirectory, withIntermediateDirectories: true)
            }
            
            for scheme in schemes {
                print("[CRRecorder] å¯åŠ¨å½•åˆ¶ä»»åŠ¡: \(scheme.id)")
                group.addTask {
                    return try await self.startRecordWithResult(scheme)
                }
            }
            
            var fileAssets: [BundleInfo.FileAsset] = []
            for try await result in group {
                fileAssets.append(contentsOf: result)
                print("[CRRecorder] å½•åˆ¶ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæ–‡ä»¶æ•°é‡: \(result.count)")
            }
            
            let bundleInfo = BundleInfo(duration: 0, files: fileAssets, version: 0)
            let result = Result(bundleURL: outputDirectory, bundleInfo: bundleInfo)
            print("[CRRecorder] æ‰€æœ‰å½•åˆ¶ä»»åŠ¡å®Œæˆï¼Œæ€»æ–‡ä»¶æ•°é‡: \(fileAssets.count)")
            return result
        }
    }
    
    func startRecordWithResult(_ scheme: SchemeItem) async throws -> [BundleInfo.FileAsset] {
        print("[CRRecorder] å¼€å§‹æ‰§è¡Œå½•åˆ¶æ–¹æ¡ˆ: \(scheme.id)")
        
        switch scheme {
        case .display(
            displayID: let displayId,
            area: let area,
            fps: let fps,
            showsCursor: let showsCursor,
            hdr: let hdr,
            useHEVC: let useHEVC,
            captureSystemAudio: let captureSystemAudio,
            queueDepth: let queueDepth,
            targetBitRate: let targetBitRate,
            filename: let filename,
            backend: let backend,
            excludedWindowTitles: let excludedWindowTitles
        ):
            print("[CRRecorder] å¼€å§‹å±å¹•å½•åˆ¶")
            return try await screenCaptureSessions?.startScreenCapture(
                displayID: displayId,
                cropRect: area,
                hdr: hdr,
                showsCursor: showsCursor,
                includeAudio: captureSystemAudio,
                excludedWindowTitles: excludedWindowTitles
            ) ?? []
        case .window(
            displayId: let displayId,
            windowID: let windowID,
            let fps,
            let showsCursor,
            hdr: let hdr,
            captureSystemAudio: let captureSystemAudio,
            filename: let filename,
            let backend,
            let queueDepth,
            let targetBitRate
        ):
            print("[CRRecorder] å¼€å§‹çª—å£å½•åˆ¶")
            return try await screenCaptureSessions?.startWindowCapture(
                windowID: windowID,
                displayID: displayId,
                hdr: hdr,
                showsCursor: showsCursor,
                includeAudio: captureSystemAudio,
                frameRate: fps,
                h265: false
            ) ?? []
        case .camera(cameraID: let cameraID, filename: let filename, cameraOptions: _):
            print("[CRRecorder] å¼€å§‹æ‘„åƒå¤´å½•åˆ¶")
            let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Movie)
            return try await recordCamera(cameraId: cameraID, fileURL: fileURL)
        case .microphone(microphoneID: let microphoneID, filename: let filename, microphoneOptions: _):
            print("[CRRecorder] å¼€å§‹éº¦å…‹é£å½•åˆ¶")
            let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Audio)
            return try await recordMicrophone(microphoneID: microphoneID, fileURL: fileURL)
        case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename, cameraOptions: _):
            print("[CRRecorder] å¼€å§‹è‹¹æœè®¾å¤‡å½•åˆ¶")
            break
        }
        return []
    }
    
    func stopRecording() async throws {
        // æ—§çš„ stopRecording ä»…ç”¨äºç®€å•è°ƒç”¨åœºæ™¯ï¼Œè¿™é‡Œç›´æ¥å¤ç”¨å¸¦ result çš„å®ç°ã€‚
        _ = try await stopRecordingWithResult()
    }
    
    
    public func stopRecordingWithResult() async throws -> Result {
        if let cached = stopAllCachedResult { return cached }
        if isStoppingAll {
            // ç®€å•ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç»™é¦–ä¸ª stop å®Œæˆè½ç›˜
            try? await Task.sleep(nanoseconds: 50_000_000)
            if let cached = stopAllCachedResult { return cached }
        }
        isStoppingAll = true
        defer { isStoppingAll = false }
        let res = try await _stopAllWithResultImpl()
        stopAllCachedResult = res
        return res
    }

    // Real stop implementation. Do not call directly; use stopRecordingWithResult().
    private func _stopAllWithResultImpl() async throws -> Result {
        
        // æŒ‰è®¾å¤‡ç±»å‹åˆ†ç»„
        let auxiliarySchemes = schemes.filter { scheme in
            switch scheme {
            case .camera, .microphone:
                return true // è¾…åŠ©è®¾å¤‡
            default:
                return false
            }
        }
        
        let primarySchemes = schemes.filter { scheme in
            switch scheme {
            case .display, .window, .appleDevice:
                return true // ä¸»è®¾å¤‡ï¼ˆå±å¹•/çª—å£å½•åˆ¶ï¼‰
            default:
                return false
            }
        }
        
        var fileAssets: [BundleInfo.FileAsset] = []

        try await withThrowingTaskGroup { group in
            for scheme in primarySchemes {
                group.addTask {
                    try await self.stopRecordingWithResult(scheme: scheme)
                }
            }
            
            for try await result in group {
                fileAssets.append(contentsOf: result)
                print("[CRRecorder] primarySchemes å½•åˆ¶ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæ–‡ä»¶æ•°é‡: \(result.count)")
            }
        }
        print("[CRRecorder] æ‰€æœ‰ primary å½•åˆ¶ä»»åŠ¡å…¨éƒ¨ç»“æŸ")

        try await withThrowingTaskGroup { group in
            for scheme in auxiliarySchemes {
                group.addTask {
                    try await self.stopRecordingWithResult(scheme: scheme)
                }
            }
            for try await result in group {
                fileAssets.append(contentsOf: result)
                print("[CRRecorder] auxiliarySchemes å½•åˆ¶ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæ–‡ä»¶æ•°é‡: \(result.count)")
            }
        }
        
        let bundleInfo = BundleInfo(duration: 0, files: fileAssets, version: 0)
        let result = Result(bundleURL: outputDirectory, bundleInfo: bundleInfo)
        print("[CRRecorder] æ‰€æœ‰å½•åˆ¶ä»»åŠ¡å®Œæˆï¼Œæ€»æ–‡ä»¶æ•°é‡: \(fileAssets.count)")
        writeBundleManifestIfPossible(bundleInfo)
        return result
    }
    
    func stopRecordingWithResult(scheme: SchemeItem) async throws -> [BundleInfo.FileAsset] {
        switch scheme {
        case .display:
            print("[CRRecorder] åœæ­¢å±å¹•å½•åˆ¶")
            return try await screenCaptureSessions?.stop() ?? []
        case .window:
            print("[CRRecorder] åœæ­¢çª—å£å½•åˆ¶")
            return try await screenCaptureSessions?.stop() ?? []
        case .camera(cameraID: let cameraID, filename: _, cameraOptions: _):
            print("[CRRecorder] åœæ­¢æ‘„åƒå¤´å½•åˆ¶")
            if let avCapture = cameraCaptures[cameraID] {
                return try await avCapture.stop()
            } else {
                return []
            }
        case .microphone(microphoneID: let microphoneID, filename: _, microphoneOptions: _):
            print("[CRRecorder] åœæ­¢éº¦å…‹é£å½•åˆ¶")
            if let avCapture = microphoneCaptures[microphoneID] {
                return try await avCapture.stop()
            } else {
                return []
            }
        case .appleDevice(appleDeviceID: let appleDeviceID, filename: _, cameraOptions: _):
            print("[CRRecorder] åœæ­¢è‹¹æœè®¾å¤‡å½•åˆ¶")
            if let avCapture = appleDeviceCaptures[appleDeviceID] {
                return try await avCapture.stop()
            } else {
                return []
            }
        }
    }
    
        func clear() {
        captureSessions.removeAll()
        cameraCaptures.removeAll()
        microphoneCaptures.removeAll()
        appleDeviceCaptures.removeAll()
        screenCaptureSessions = nil
    }
    
    public enum SchemeItem: Identifiable, Hashable, Equatable, Sendable {
        case display(
            displayID: CGDirectDisplayID,
            area: CGRect?,
            fps: Int,
            showsCursor: Bool,
            hdr: Bool,
            useHEVC: Bool,
            captureSystemAudio: Bool,
            queueDepth: Int?,
            targetBitRate: Int?,
            filename: String,
            backend: ScreenBackend,
            excludedWindowTitles: [String]
        )
        case window(
            displayId: CGDirectDisplayID,
            windowID: CGWindowID,
            fps: Int,
            showsCursor: Bool,
            hdr: Bool,
            captureSystemAudio: Bool,
            filename: String,
            backend: ScreenBackend,
            queueDepth: Int?,
            targetBitRate: Int?
        )
        case camera(
            cameraID: String,
            filename: String,
            cameraOptions: CameraRecordingOptions
        )
        case microphone(
            microphoneID: String,
            filename: String,
            microphoneOptions: MicrophoneProcessingOptions
        )
        case appleDevice(
            appleDeviceID: String,
            filename: String,
            cameraOptions: CameraRecordingOptions
        )
        
        public var id: String {
            switch self {
            case .display(let displayId, _, _, _, _, _, _, _, _, _, _, _):
                return "display_\(displayId)"
            case .window(let displayId, let windowID, _, _, _, _, _, _, _, _):
                return "window_\(displayId)_\(windowID)"
            case .camera(let cameraID, _, _):
                return "camera_\(cameraID)"
            case .microphone(let microphoneID, _, _):
                return "microphone_\(microphoneID)"
            case .appleDevice(let appleDeviceID, _, _):
                return "apple_device_\(appleDeviceID)"
            }
        }
    }
    
    public struct Result: Sendable {
        public var bundleURL: URL
        public var bundleInfo: BundleInfo
    }
    
    public struct BundleInfo: Codable, Sendable {
        public var duration: TimeInterval
        public var files: [FileAsset]
        public var version: Int
        
        public struct FileAsset: Codable, Sendable {
            public var filename: String
            public var recordingSize: Size?
            public var tyle: FileAssetType
            public var videoDimensions: Size?
            public var recordingStartTimestamp: CFAbsoluteTime?
            public var recordingEndTimestamp: CFAbsoluteTime?
            
            public init(
                filename: String,
                recordingSize: Size? = nil,
                tyle: FileAssetType,
                videoDimensions: Size? = nil,
                recordingStartTimestamp: CFAbsoluteTime? = nil,
                recordingEndTimestamp: CFAbsoluteTime? = nil
            ) {
                self.filename = filename
                self.recordingSize = recordingSize
                self.tyle = tyle
                self.videoDimensions = videoDimensions
                self.recordingStartTimestamp = recordingStartTimestamp
                self.recordingEndTimestamp = recordingEndTimestamp
            }
        }
        
        public struct Size: Codable, Sendable {
            public var width: Int
            public var height: Int
        }
        
        public enum FileAssetType: String, Equatable, Codable, Sendable {
            case appleDevice
            case audio
            case mouse
            case screen
            case systemAudio
            case topWindow
            case webcam
        }
    }
}

// MARK: - Helpers
extension CRRecorder {
    /// æ ¹æ® backend åˆ›å»ºå¯¹åº”çš„å±å¹•å½•åˆ¶å®ç°ï¼›é›†ä¸­åšä¸€æ¬¡ switchï¼Œåç»­æµç¨‹ç»Ÿä¸€èµ° `ScreenRecorderBackend` æ¥å£ã€‚
    fileprivate func makeScreenBackend(
        backend: ScreenBackend,
        filename: String,
        fps: Int,
        queueDepth: Int?,
        targetBitRate: Int?,
        showsCursor: Bool,
        useHEVC: Bool
    ) -> ScreenRecorderBackend {
        // å†…éƒ¨ä»ç„¶ä½¿ç”¨ ScreenRecorderOptions ä½œä¸ºèšåˆä½“ï¼Œä½†è¯¥ç±»å‹ä¸å†æš´éœ²ç»™å¤–éƒ¨ APIã€‚
        let options = ScreenRecorderOptions(
            fps: fps,
            queueDepth: queueDepth,
            targetBitRate: targetBitRate,
            showsCursor: showsCursor,
            useHEVC: useHEVC
        )
        let filePath = outputDirectory
            .appendingPathComponent(filename)
            .appendingPathExtension("mov")
            .path(percentEncoded: false)
        switch backend {
        case .screenCaptureKit:
            let recorder = ScreenCaptureRecorder(filePath: filePath, options: options)
            recorder.errorHandler = { [weak self] error in
                guard let self else { return }
                NSLog("ğŸ”¥ [CR_RECORDER_ERROR] CRRecorder æ¥æ”¶åˆ°å±å¹•/çª—å£å½•åˆ¶é”™è¯¯: %@", error.localizedDescription)
                self.onInterupt(error)
            }
            return recorder
        case .avFoundation:
            let backendRecorder = AVFoundationScreenRecorderBackend(outputDirectory: outputDirectory, baseFilename: filename, options: options)
            backendRecorder.errorHandler = { [weak self] error in
                guard let self else { return }
                let ns = error as NSError
                NSLog("ğŸ”¥ [CR_RECORDER_AVSCREEN_ERROR] domain=%@ code=%ld msg=%@", ns.domain, ns.code, ns.localizedDescription)
                self.onInterupt(error)
            }
            return backendRecorder
        }
    }

    // MARK: - Persist manifest
    fileprivate func writeBundleManifestIfPossible(_ info: BundleInfo) {
        do {
            let encoder = JSONEncoder()
            encoder.outputFormatting = [.prettyPrinted, .withoutEscapingSlashes]
            let data = try encoder.encode(info)
            if !FileManager.default.fileExists(atPath: outputDirectory.path) {
                try FileManager.default.createDirectory(at: outputDirectory, withIntermediateDirectories: true)
            }
            let url = outputDirectory.appendingPathComponent("bundle.json")
            try data.write(to: url, options: .atomic)
            print("[CRRecorder] å·²å†™å…¥æ¸…å•: \(url.path)")
        } catch {
            print("[CRRecorder] å†™å…¥æ¸…å•å¤±è´¥: \(error.localizedDescription)")
        }
    }
}
