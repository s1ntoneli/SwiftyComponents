//
//  File.swift
//  CoreRecorder
//
//  Created by lixindong on 2025/6/6.
//

import Foundation
import AVFoundation
import Combine

public class CRRecorder: @unchecked Sendable {
    
    var outputDirectory: URL
    var schemes: [SchemeItem]
    var captureSessions: [String: AVCaptureSession] = [:]
    var captureDelegates: [String: CaptureRecordingDelegate] = [:]
    var screenCaptureSessions: ScreenCaptureRecorder?
    
    var appleDeviceCaptures: [String: CRAppleDeviceRecording] = [:]
    var cameraCaptures: [String: CRCameraRecording] = [:]
    var microphoneCaptures: [String: CRMicrophoneRecording] = [:]
    // ÂèØÂàáÊç¢ÁöÑÈ∫¶ÂÖãÈ£éÂΩïÂà∂ÂêéÁ´ØÔºàÈªòËÆ§Ê≤øÁî®ÊóßÊñπÊ°àÔºâ
//    public var microphoneBackend: CRMicrophoneRecording.Backend = .fileOutput
    
    nonisolated(unsafe)
    var onInterupt: (Error) -> Void = {_ in}
    
    var resultSubject: PassthroughSubject<Result, Error> = .init()
    var audioLevelSubject: PassthroughSubject<Float, Never> = .init()
    
    init(_ schemes: [SchemeItem], outputDirectory: URL) {
        self.schemes = schemes
        self.outputDirectory = outputDirectory
        print("[CRRecorder] ÂàùÂßãÂåñÂΩïÂà∂Âô®ÔºåËæìÂá∫ÁõÆÂΩï: \(outputDirectory.path), ÂΩïÂà∂ÊñπÊ°àÊï∞Èáè: \(schemes.count)")
    }
    
    func prepare(_ schemes: [SchemeItem]) async throws {
        print("[CRRecorder] ÂºÄÂßãÂáÜÂ§áÂΩïÂà∂ÊñπÊ°àÔºåÂÖ± \(schemes.count) ‰∏™")
        self.schemes = schemes
        
        for scheme in schemes {
            print("[CRRecorder] ÂáÜÂ§áÂΩïÂà∂ÊñπÊ°à: \(scheme.id)")
            switch scheme {
            case .display(let displayId, let area, let hdr, let captureSystemAudio, let filename):
                print("[CRRecorder] ÂáÜÂ§áÂ±èÂπïÂΩïÂà∂ - ÊòæÁ§∫Âô®ID: \(displayId), Êñá‰ª∂Âêç: \(filename), HDR: \(hdr), Á≥ªÁªüÈü≥È¢ë: \(captureSystemAudio)")
                screenCaptureSessions = ScreenCaptureRecorder(filePath: outputDirectory.appendingPathComponent(filename).appendingPathExtension("mov").path(percentEncoded: false))
                screenCaptureSessions?.errorHandler = {
                    NSLog("üî• [CR_RECORDER_ERROR] CRRecorder Êé•Êî∂Âà∞Â±èÂπïÂΩïÂà∂ÈîôËØØ: %@", $0.localizedDescription)
                    self.onInterupt($0)
                }
            case .window(displayId: let displayId, windowID: let windowID, hdr: let hdr, captureSystemAudio: let captureSystemAudio, filename: let filename):
                print("[CRRecorder] ÂáÜÂ§áÁ™óÂè£ÂΩïÂà∂ - ÊòæÁ§∫Âô®ID: \(displayId), Á™óÂè£ID: \(windowID), Êñá‰ª∂Âêç: \(filename)")
                screenCaptureSessions = ScreenCaptureRecorder(filePath: outputDirectory.appendingPathComponent(filename).appendingPathExtension("mov").path(percentEncoded: false))
                screenCaptureSessions?.errorHandler = {
                    NSLog("üî• [CR_RECORDER_ERROR] CRRecorder Êé•Êî∂Âà∞Á™óÂè£ÂΩïÂà∂ÈîôËØØ: %@", $0.localizedDescription)
                    self.onInterupt($0)
                }
            case .camera(cameraID: let cameraID, filename: let filename):
                print("[CRRecorder] ÂáÜÂ§áÊëÑÂÉèÂ§¥ÂΩïÂà∂ - ÊëÑÂÉèÂ§¥ID: \(cameraID), Êñá‰ª∂Âêç: \(filename)")
//                prepareCameraSession(cameraID: cameraID, filename: filename)
                let cameraRecording = CRCameraRecording()
                cameraRecording.onError = { err in
                    NSLog("üìπ [CR_RECORDER_CAMERA_ERROR] CRRecorder Êé•Êî∂Âà∞ÊëÑÂÉèÂ§¥ÈîôËØØ: %@", err.localizedDescription)
                    self.onInterupt(err)
                }
                cameraRecording.onComplete = { [unowned self] url in}
                try await cameraRecording.prepare(cameraId: cameraID)
                
                cameraCaptures[cameraID] = cameraRecording
                break
            case .microphone(microphoneID: let microphoneID, filename: let filename):
                print("[CRRecorder] ÂáÜÂ§áÈ∫¶ÂÖãÈ£éÂΩïÂà∂ - È∫¶ÂÖãÈ£éID: \(microphoneID), Êñá‰ª∂Âêç: \(filename)")
//                prepareMicrophoneSession(microphoneID: microphoneID, filename: filename)
                let microphoneRecording = CRMicrophoneRecording()
                microphoneRecording.audioLevelHandler = { [weak self] level, peak in
                    self?.audioLevelSubject.send(level)
                }
                try await microphoneRecording.prepare(microphoneID: microphoneID)
                microphoneCaptures[microphoneID] = microphoneRecording
                break
            case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename):
                print("[CRRecorder] ÂáÜÂ§áËãπÊûúËÆæÂ§áÂΩïÂà∂ - ËÆæÂ§áID: \(appleDeviceID), Êñá‰ª∂Âêç: \(filename)")
                let appleDeviceRecording = CRAppleDeviceRecording()
                try await appleDeviceRecording.prepare(deviceId: appleDeviceID)
                appleDeviceCaptures[appleDeviceID] = appleDeviceRecording
                break
            }
        }
        print("[CRRecorder] ÂΩïÂà∂ÊñπÊ°àÂáÜÂ§áÂÆåÊàê")
    }
    
    func startRecording() async throws {
        // Á°Æ‰øùËæìÂá∫ÁõÆÂΩïÂ≠òÂú®
        if !FileManager.default.fileExists(atPath: outputDirectory.path) {
            print("[CRRecorder] ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï: \(outputDirectory.path)")
            try FileManager.default.createDirectory(at: outputDirectory, withIntermediateDirectories: true)
        }

        // ÊåâËÆæÂ§áÁ±ªÂûãÂàÜÁªÑ
        let auxiliarySchemes = schemes.filter { scheme in
            switch scheme {
            case .camera, .microphone:
                return true // ËæÖÂä©ËÆæÂ§á
            default:
                return false
            }
        }
        
        let primarySchemes = schemes.filter { scheme in
            switch scheme {
            case .display, .window, .appleDevice:
                return true // ‰∏ªËÆæÂ§áÔºàÂ±èÂπï/Á™óÂè£ÂΩïÂà∂Ôºâ
            default:
                return false
            }
        }
        
        try await withThrowingTaskGroup { group  in
            for scheme in auxiliarySchemes {
                group.addTask {
                    try await self.startRecord(scheme: scheme)
                }
            }
            try await group.waitForAll()
        }
        print("[CRRecorder] ÊâÄÊúâ auxiliary ÂΩïÂà∂‰ªªÂä°ÂÖ®ÈÉ®ÂºÄÂßã")
        try await withThrowingTaskGroup { group in
            for scheme in primarySchemes {
                group.addTask {
                    try await self.startRecord(scheme: scheme)
                }
            }
            try await group.waitForAll()
        }
        
        print("[CRRecorder] ÊâÄÊúâÂΩïÂà∂‰ªªÂä°ÂÖ®ÈÉ®ÂºÄÂßã")
        packLastResult()
    }
    
    // Êï¥ÁêÜ result
    public func packLastResult() -> Result? {
        var fileAssets: [BundleInfo.FileAsset] = []
        for scheme in schemes {
            switch scheme {
            case .display(displayID: let displayID, area: let area, hdr: let hdr, captureSystemAudio: let captureSystemAudio, filename: let filename):
                let assets = screenCaptureSessions?.packLastResult() ?? []
                fileAssets.append(contentsOf: assets)
            case .window(displayId: let displayId, windowID: let windowID, hdr: let hdr, captureSystemAudio: let captureSystemAudio, filename: let filename):
                let assets = screenCaptureSessions?.packLastResult() ?? []
                fileAssets.append(contentsOf: assets)
            case .camera(cameraID: let cameraID, filename: let filename):
                if let cameraCapture = cameraCaptures[cameraID] {
                    let fileAsset = cameraCapture.packLastResult()
                    fileAssets.append(contentsOf: fileAsset)
                }
            case .microphone(microphoneID: let microphoneID, filename: let filename):
                if let avCapture = microphoneCaptures[microphoneID] {
                    let fileAsset = avCapture.packLastResult()
                    fileAssets.append(contentsOf: fileAsset)
                }
            case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename):
                if let avCapture = appleDeviceCaptures[appleDeviceID] {
                    let fileAsset = avCapture.packLastResult()
                    fileAssets.append(contentsOf: fileAsset)
                }
            }
        }
        
        let result = Result(bundleURL: outputDirectory, bundleInfo: BundleInfo(duration: 0, files: fileAssets, version: 0))
        print("[CRRecorder] ÊâÄÊúâÂΩïÂà∂‰ªªÂä°ÂÆåÊàêÔºåÊÄªÊñá‰ª∂Êï∞Èáè: \(fileAssets.count)")
        
        resultSubject.send(result)
        
        return result
    }
    
    func startRecord(scheme: SchemeItem) async throws {
        switch scheme {
        case .display(displayID: let displayID, area: let area, hdr: let hdr, captureSystemAudio: let captureSystemAudio, filename: let filename):
            try await screenCaptureSessions?.startScreenCapture(displayID: displayID, cropRect: area, hdr: hdr, showsCursor: false, includeAudio: captureSystemAudio)
        case .window(displayId: let displayId, windowID: let windowID, hdr: let hdr, captureSystemAudio: let captureSystemAudio, filename: let filename):
            try await screenCaptureSessions?.startWindowCapture(windowID: windowID, displayID: displayId, hdr: hdr, includeAudio: captureSystemAudio)
        case .camera(cameraID: let cameraID, filename: let filename):
            if let cameraCapture = cameraCaptures[cameraID] {
                let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Movie)
                try await cameraCapture.start(fileURL: fileURL)
            }
        case .microphone(microphoneID: let microphoneID, filename: let filename):
            if let avCapture = microphoneCaptures[microphoneID] {
                let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Audio)
                try await avCapture.start(fileURL: fileURL)
            }
        case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename):
            if let avCapture = appleDeviceCaptures[appleDeviceID] {
                let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .movie).appendingPathExtension("mov")
                try await avCapture.start(fileURL: fileURL)
            }
        }
    }
    
    func startRecordingWithResult() async throws -> Result {
        print("[CRRecorder] ÂºÄÂßãÂΩïÂà∂")
        return try await withThrowingTaskGroup { group in
            // Á°Æ‰øùËæìÂá∫ÁõÆÂΩïÂ≠òÂú®
            if !FileManager.default.fileExists(atPath: outputDirectory.path) {
                print("[CRRecorder] ÂàõÂª∫ËæìÂá∫ÁõÆÂΩï: \(outputDirectory.path)")
                try FileManager.default.createDirectory(at: outputDirectory, withIntermediateDirectories: true)
            }
            
            for scheme in schemes {
                print("[CRRecorder] ÂêØÂä®ÂΩïÂà∂‰ªªÂä°: \(scheme.id)")
                group.addTask {
                    return try await self.startRecordWithResult(scheme)
                }
            }
            
            var fileAssets: [BundleInfo.FileAsset] = []
            for try await result in group {
                fileAssets.append(contentsOf: result)
                print("[CRRecorder] ÂΩïÂà∂‰ªªÂä°ÂÆåÊàêÔºåÁîüÊàêÊñá‰ª∂Êï∞Èáè: \(result.count)")
            }
            
            let bundleInfo = BundleInfo(duration: 0, files: fileAssets, version: 0)
            let result = Result(bundleURL: outputDirectory, bundleInfo: bundleInfo)
            print("[CRRecorder] ÊâÄÊúâÂΩïÂà∂‰ªªÂä°ÂÆåÊàêÔºåÊÄªÊñá‰ª∂Êï∞Èáè: \(fileAssets.count)")
            return result
        }
    }
    
    func startRecordWithResult(_ scheme: SchemeItem) async throws -> [BundleInfo.FileAsset] {
        print("[CRRecorder] ÂºÄÂßãÊâßË°åÂΩïÂà∂ÊñπÊ°à: \(scheme.id)")
        
        switch scheme {
        case .display(let displayId, let area, let hdr, let captureSystemAudio, let filename):
            print("[CRRecorder] ÂºÄÂßãÂ±èÂπïÂΩïÂà∂")
            return try await screenCaptureSessions?.startScreenCapture(displayID: displayId, cropRect: area, hdr: hdr, showsCursor: false, includeAudio: captureSystemAudio) ?? []
        case .window(displayId: let displayId, windowID: let windowID, hdr: let hdr, captureSystemAudio: let captureSystemAudio, filename: let filename):
            print("[CRRecorder] ÂºÄÂßãÁ™óÂè£ÂΩïÂà∂")
            return try await screenCaptureSessions?.startWindowCapture(windowID: windowID, displayID: displayId, hdr: hdr, includeAudio: captureSystemAudio) ?? []
        case .camera(cameraID: let cameraID, filename: let filename):
            print("[CRRecorder] ÂºÄÂßãÊëÑÂÉèÂ§¥ÂΩïÂà∂")
            let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Movie)
            return try await recordCamera(cameraId: cameraID, fileURL: fileURL)
        case .microphone(microphoneID: let microphoneID, filename: let filename):
            print("[CRRecorder] ÂºÄÂßãÈ∫¶ÂÖãÈ£éÂΩïÂà∂")
            let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Audio)
            return try await recordMicrophone(microphoneID: microphoneID, fileURL: fileURL)
        case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename):
            print("[CRRecorder] ÂºÄÂßãËãπÊûúËÆæÂ§áÂΩïÂà∂")
            break
        }
        return []
    }
    
    func stopRecording() async throws {
        print("[CRRecorder] ÂºÄÂßãÂÅúÊ≠¢ÂΩïÂà∂")
        try await withThrowingTaskGroup { group in
            for scheme in schemes {
                group.addTask {
                    print("[CRRecorder] ÂÅúÊ≠¢ÂΩïÂà∂ÊñπÊ°à: \(scheme.id)")
                    switch scheme {
                    case .display(let displayId, let area, let hdr, let captureSystemAudio, let filename):
                        print("[CRRecorder] ÂÅúÊ≠¢Â±èÂπïÂΩïÂà∂")
                        try await self.screenCaptureSessions?.stop()
                        break
                    case .window(displayId: let displayId, windowID: let windowID, hdr: let hdr, captureSystemAudio: let captureSystemAudio, filename: let filename):
                        print("[CRRecorder] ÂÅúÊ≠¢Á™óÂè£ÂΩïÂà∂")
                        try await self.screenCaptureSessions?.stop()
                        break
                    case .camera(cameraID: let cameraID, filename: let filename):
                        print("[CRRecorder] ÂÅúÊ≠¢ÊëÑÂÉèÂ§¥ÂΩïÂà∂")
                        //                    let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Movie)
                        //                    try await recordCamera(cameraId: cameraID, fileURL: fileURL)
                        try await self.stopRecording(deviceID: cameraID)
                    case .microphone(microphoneID: let microphoneID, filename: let filename):
                        print("[CRRecorder] ÂÅúÊ≠¢È∫¶ÂÖãÈ£éÂΩïÂà∂")
                        //                    let fileURL = outputDirectory.appendingPathComponent(filename, conformingTo: .mpeg4Audio)
                        //                    try await recordMicrophone(microphoneId: microphoneID, fileURL: fileURL)
                        try await self.stopRecording(deviceID: microphoneID)
                    case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename):
                        print("[CRRecorder] ÂÅúÊ≠¢ËãπÊûúËÆæÂ§áÂΩïÂà∂")
                        break
                    }
                }
            }
            for try await result in group {}
        }
        print("[CRRecorder] ÊâÄÊúâÂΩïÂà∂Â∑≤ÂÅúÊ≠¢")
    }
    
    
    public func stopRecordingWithResult() async throws -> Result {
        
        // ÊåâËÆæÂ§áÁ±ªÂûãÂàÜÁªÑ
        let auxiliarySchemes = schemes.filter { scheme in
            switch scheme {
            case .camera, .microphone:
                return true // ËæÖÂä©ËÆæÂ§á
            default:
                return false
            }
        }
        
        let primarySchemes = schemes.filter { scheme in
            switch scheme {
            case .display, .window, .appleDevice:
                return true // ‰∏ªËÆæÂ§áÔºàÂ±èÂπï/Á™óÂè£ÂΩïÂà∂Ôºâ
            default:
                return false
            }
        }
        
        var fileAssets: [BundleInfo.FileAsset] = []

        try await withThrowingTaskGroup { group in
            for scheme in primarySchemes {
                group.addTask {
                    try await self.stopRecordingWithResult(scheme: scheme)
                }
            }
            
            for try await result in group {
                fileAssets.append(contentsOf: result)
                print("[CRRecorder] primarySchemes ÂΩïÂà∂‰ªªÂä°ÂÆåÊàêÔºåÁîüÊàêÊñá‰ª∂Êï∞Èáè: \(result.count)")
            }
        }
        print("[CRRecorder] ÊâÄÊúâ primary ÂΩïÂà∂‰ªªÂä°ÂÖ®ÈÉ®ÁªìÊùü")

        try await withThrowingTaskGroup { group in
            for scheme in auxiliarySchemes {
                group.addTask {
                    try await self.stopRecordingWithResult(scheme: scheme)
                }
            }
            for try await result in group {
                fileAssets.append(contentsOf: result)
                print("[CRRecorder] auxiliarySchemes ÂΩïÂà∂‰ªªÂä°ÂÆåÊàêÔºåÁîüÊàêÊñá‰ª∂Êï∞Èáè: \(result.count)")
            }
        }
        
        let bundleInfo = BundleInfo(duration: 0, files: fileAssets, version: 0)
        let result = Result(bundleURL: outputDirectory, bundleInfo: bundleInfo)
        print("[CRRecorder] ÊâÄÊúâÂΩïÂà∂‰ªªÂä°ÂÆåÊàêÔºåÊÄªÊñá‰ª∂Êï∞Èáè: \(fileAssets.count)")
        return result
    }
    
    func stopRecordingWithResult(scheme: SchemeItem) async throws -> [BundleInfo.FileAsset] {
        switch scheme {
        case .display(let displayId, let area, let hdr, let captureSystemAudio, let filename):
            print("[CRRecorder] ÂÅúÊ≠¢Â±èÂπïÂΩïÂà∂")
            return try await screenCaptureSessions?.stop() ?? []
        case .window(displayId: let displayId, windowID: let windowID, hdr: let hdr, captureSystemAudio: let captureSystemAudio, filename: let filename):
            print("[CRRecorder] ÂÅúÊ≠¢Á™óÂè£ÂΩïÂà∂")
            return try await screenCaptureSessions?.stop() ?? []
        case .camera(cameraID: let cameraID, filename: let filename):
            print("[CRRecorder] ÂÅúÊ≠¢ÊëÑÂÉèÂ§¥ÂΩïÂà∂")
            if let avCapture = cameraCaptures[cameraID] {
                return try await avCapture.stop()
            } else {
                return []
            }
        case .microphone(microphoneID: let microphoneID, filename: let filename):
            print("[CRRecorder] ÂÅúÊ≠¢È∫¶ÂÖãÈ£éÂΩïÂà∂")
            if let avCapture = microphoneCaptures[microphoneID] {
                return try await avCapture.stop()
            } else {
                return []
            }
        case .appleDevice(appleDeviceID: let appleDeviceID, filename: let filename):
            print("[CRRecorder] ÂÅúÊ≠¢ËãπÊûúËÆæÂ§áÂΩïÂà∂")
            if let avCapture = appleDeviceCaptures[appleDeviceID] {
                return try await avCapture.stop()
            } else {
                return []
            }
        }
        return []
    }
    
    func clear() {
        captureSessions.removeAll()
        cameraCaptures.removeAll()
        microphoneCaptures.removeAll()
        appleDeviceCaptures.removeAll()
        screenCaptureSessions = nil
    }
    
    public enum SchemeItem: Identifiable, Hashable, Equatable, Sendable {
        case display(displayID: CGDirectDisplayID, area: CGRect?, hdr: Bool, captureSystemAudio: Bool, filename: String)
        case window(displayId: CGDirectDisplayID, windowID: CGWindowID, hdr: Bool, captureSystemAudio: Bool, filename: String)
        case camera(cameraID: String, filename: String)
        case microphone(microphoneID: String, filename: String)
        case appleDevice(appleDeviceID: String, filename: String)
        
        public var id: String {
            switch self {
            case .display(let displayId, _, _, _, _):
                return "display_\(displayId)"
            case .window(let displayId, let windowID, _, _, _):
                return "window_\(displayId)_\(windowID)"
            case .camera(let cameraID, _):
                return "camera_\(cameraID)"
            case .microphone(let microphoneID, _):
                return "microphone_\(microphoneID)"
            case .appleDevice(let appleDeviceID, _):
                return "apple_device_\(appleDeviceID)"
            }
        }
    }
    
    public struct Result: Sendable {
        public var bundleURL: URL
        public var bundleInfo: BundleInfo
    }
    
    public struct BundleInfo: Sendable {
        public var duration: TimeInterval
        public var files: [FileAsset]
        public var version: Int
        
        public struct FileAsset: Codable, Sendable {
            public var filename: String
            public var recordingSize: Size?
            public var tyle: FileAssetType
            public var videoDimensions: Size?
            public var recordingStartTimestamp: CFAbsoluteTime?
            public var recordingEndTimestamp: CFAbsoluteTime?
            
            public init(
                filename: String,
                recordingSize: Size? = nil,
                tyle: FileAssetType,
                videoDimensions: Size? = nil,
                recordingStartTimestamp: CFAbsoluteTime? = nil,
                recordingEndTimestamp: CFAbsoluteTime? = nil
            ) {
                self.filename = filename
                self.recordingSize = recordingSize
                self.tyle = tyle
                self.videoDimensions = videoDimensions
                self.recordingStartTimestamp = recordingStartTimestamp
                self.recordingEndTimestamp = recordingEndTimestamp
            }
        }
        
        public struct Size: Codable, Sendable {
            public var width: Int
            public var height: Int
        }
        
        public enum FileAssetType: String, Equatable, Codable, Sendable {
            case appleDevice
            case audio
            case mouse
            case screen
            case systemAudio
            case topWindow
            case webcam
        }
    }
}
