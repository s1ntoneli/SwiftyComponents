//
//  CRRecorder+Record.swift
//  CoreRecorder
//
//  Created by lixindong on 2025/6/6.
//

import AVFoundation
import ReplayKit
//
//enum RecordingError: Error {
//    case deviceNotFound
//    case cannotAddInput
//    case cannotAddOutput
//    case sessionFailedToStart
//    case sessionNotRunning
//    case outputNotConfigured
//    case notPrepared
//    
//    var localizedDescription: String {
//        switch self {
//        case .deviceNotFound:
//            return "æ‰¾ä¸åˆ°æŒ‡å®šçš„å½•åˆ¶è®¾å¤‡"
//        case .cannotAddInput:
//            return "æ— æ³•æ·»åŠ è¾“å…¥è®¾å¤‡åˆ°ä¼šè¯"
//        case .cannotAddOutput:
//            return "æ— æ³•æ·»åŠ è¾“å‡ºè®¾å¤‡åˆ°ä¼šè¯"
//        case .sessionFailedToStart:
//            return "ä¼šè¯å¯åŠ¨å¤±è´¥"
//        case .sessionNotRunning:
//            return "ä¼šè¯æœªè¿è¡Œ"
//        case .outputNotConfigured:
//            return "è¾“å‡ºè®¾å¤‡æœªé…ç½®"
//        case .notPrepared:
//            return "å½•åˆ¶æœªå‡†å¤‡å°±ç»ªï¼Œè¯·å…ˆè°ƒç”¨ prepare() æ–¹æ³•"
//        }
//    }
//}

class CRCameraRecording {
    var session: AVCaptureSession?
    var delegate: CaptureRecordingDelegate = CaptureRecordingDelegate()
    var startTime: CFAbsoluteTime = 0
    var endTime: CFAbsoluteTime = 0
    var startURL: URL? = nil
    var isPrepared: Bool = false
    // å¯¹å¤–å›è°ƒï¼ˆä¾› CRRecorder æ³¨å…¥ï¼‰
    var onError: (Error) -> Void = { _ in }
    var onComplete: (URL) -> Void = { _ in }
    // å¯é…ç½®å‚æ•°ï¼ˆåˆ†è¾¨ç‡/ç¼–ç å™¨/ç ç‡èŒƒå›´ï¼‰
    var options: CameraRecordingOptions = .init()

    // æ‰‹åŠ¨åˆ‡æ¢åç«¯ï¼šå¦‚éœ€å›é€€ä¸ºæ–‡ä»¶è¾“å‡ºï¼Œå°†ä¸‹è¡Œæ›¿æ¢ä¸º FileOutputCamBackend()
    private let backend: CameraBackend = AssetWriterCamBackend()

    init() {
        print("ğŸ“¹ CRCameraRecording åˆå§‹åŒ–")
        // å°†åº•å±‚å§”æ‰˜äº‹ä»¶æ¡¥æ¥ç»™å¤–éƒ¨å›è°ƒ
        delegate.onError = { [unowned self] error in
            onError(error)
        }
        delegate.onComplete = { [unowned self] url in
            onComplete(url)
        }
    }

    func prepare(cameraId: String) async throws {
        print("ğŸ”§ æ‘„åƒå¤´å½•åˆ¶å‡†å¤‡ä¸­... - è®¾å¤‡ID: \(cameraId)")

        let device: AVCaptureDevice
        if cameraId == "default" {
            guard let d = AVCaptureDevice.default(for: .video) else { throw RecordingError.deviceNotFound }
            device = d
        } else if let specificDevice = AVCaptureDevice(uniqueID: cameraId) {
            device = specificDevice
        } else {
            guard let d = AVCaptureDevice.default(for: .video) else { throw RecordingError.deviceNotFound }
            device = d
        }

        let input = try AVCaptureDeviceInput(device: device)
        let session = AVCaptureSession()
        session.beginConfiguration()
        // åˆ†è¾¨ç‡å¼€å…³ï¼ˆé»˜è®¤ä¸º 720pï¼Œå¯ç½®ç©ºç»´æŒè®¾å¤‡åŸç”Ÿåˆ†è¾¨ç‡ï¼‰
        if let preset = options.preset, session.canSetSessionPreset(preset) {
            session.sessionPreset = preset
        }
        guard session.canAddInput(input) else { throw RecordingError.cannotAddInput }
        session.addInput(input)
        // ä¸å¼ºåˆ¶é™å¸§ï¼Œä¿æŒè®¾å¤‡é»˜è®¤æˆ–ç”¨æˆ·è®¾ç½®çš„é«˜å¸§ç‡ï¼Œä½“ç§¯æ§åˆ¶äº¤ç”±ç¼–ç å™¨ç ç‡å®Œæˆã€‚
        session.commitConfiguration()

        // ä¼ å…¥ç¼–ç ä¸ç ç‡å¼€å…³
        backend.apply(options: options)
        try backend.configure(session: session, device: device, delegate: delegate, queue: DispatchQueue(label: "com.recorderkit.camera.video", qos: .userInitiated))

        session.startRunning()
        guard session.isRunning else { throw RecordingError.sessionFailedToStart }
        self.session = session
        self.isPrepared = true
        print("âœ… æ‘„åƒå¤´å½•åˆ¶å‡†å¤‡å®Œæˆï¼Œæ•°æ®æµå·²å¯åŠ¨")
    }

    func start(fileURL: URL) async throws {
        print("ğŸ¬ å¼€å§‹æ‘„åƒå¤´å½•åˆ¶: \(fileURL.lastPathComponent)")
        guard isPrepared else { throw RecordingError.notPrepared }
        guard session?.isRunning == true else { throw RecordingError.sessionNotRunning }
        self.startURL = fileURL
        backend.onFirstPTS = { [weak self] time in self?.startTime = time.seconds }
        try await backend.start(fileURL: fileURL)
    }

    func startWithPrepare(cameraId: String, fileURL: URL) async throws {
        try await prepare(cameraId: cameraId)
        try await start(fileURL: fileURL)
    }

    func stop() async throws -> [CRRecorder.BundleInfo.FileAsset] {
        print("ğŸ›‘ åœæ­¢æ‘„åƒå¤´å½•åˆ¶")
        endTime = CFAbsoluteTimeGetCurrent()
        let url = try await backend.stop()
        if let s = session { AVCaptureSessionHelper.stopRecordingStep2Close(avSession: s) }
        if let url {
            return [CRRecorder.BundleInfo.FileAsset(filename: url.lastPathComponent, tyle: .webcam, recordingStartTimestamp: startTime, recordingEndTimestamp: endTime)]
        }
        return []
    }

    func packLastResult() -> [CRRecorder.BundleInfo.FileAsset] {
        if let fileURL = startURL {
            let end = CFAbsoluteTimeGetCurrent()
            let asset = CRRecorder.BundleInfo.FileAsset(filename: fileURL.lastPathComponent, tyle: .webcam, recordingStartTimestamp: startTime, recordingEndTimestamp: end)
            return [asset]
        }
        return []
    }
}

class CRAppleDeviceRecording {
    var session: AVCaptureSession?
    var delegate: CaptureRecordingDelegate = CaptureRecordingDelegate()
    var startTime: CFAbsoluteTime = 0
    var endTime: CFAbsoluteTime = 0
    var startURL: URL? = nil
    var isPrepared: Bool = false
    // å¯¹å¤–å›è°ƒ
    var onError: (Error) -> Void = { _ in }
    var onComplete: ([CRRecorder.BundleInfo.FileAsset]) -> Void = { _ in }

    // å¤ç”¨ç›¸æœºåç«¯ï¼ˆFileOutput æˆ– AssetWriterï¼‰ï¼Œé»˜è®¤ FileOutput
    private let backend: CameraBackend = AssetWriterCamBackend()
    var options: CameraRecordingOptions = .init()

    init() {
        NSLog("ğŸ“¹ CRAppleDeviceRecording åˆå§‹åŒ–")
        delegate.onError = { [unowned self] error in onError(error) }
        delegate.onComplete = { [unowned self] url in
            endTime = CFAbsoluteTimeGetCurrent()
            let asset = CRRecorder.BundleInfo.FileAsset(filename: url.lastPathComponent, tyle: .appleDevice, recordingStartTimestamp: startTime, recordingEndTimestamp: endTime)
            onComplete([asset])
        }
    }

    func prepare(deviceId: String) async throws {
        NSLog("ğŸ”§ AppleDeviceå½•åˆ¶å‡†å¤‡ä¸­... - è®¾å¤‡ID: \(deviceId)")
        guard let device = AVCaptureDevice(uniqueID: deviceId) else { throw RecordingError.deviceNotFound }
        let input = try AVCaptureDeviceInput(device: device)
        let session = AVCaptureSession()
        session.beginConfiguration()
        guard session.canAddInput(input) else { throw RecordingError.cannotAddInput }
        session.addInput(input)
        // è¯•å›¾ä¸º Apple è®¾å¤‡æ·»åŠ å¯¹åº”çš„éŸ³é¢‘è¾“å…¥ï¼ˆåç§°åŒ¹é…ï¼‰
        // QuickTime çš„åšæ³•æ˜¯åŒæ—¶é€‰æ‹© iPhone ä½œä¸ºè§†é¢‘æºå’Œéº¦å…‹é£æº
        session.commitConfiguration()

        backend.apply(options: options)
        try backend.configure(session: session, device: device, delegate: delegate, queue: DispatchQueue(label: "com.recorderkit.appledevice.video", qos: .userInitiated))

        session.startRunning()
        guard session.isRunning else { throw RecordingError.sessionFailedToStart }

        self.session = session
        self.isPrepared = true
        NSLog("âœ… AppleDeviceå½•åˆ¶å‡†å¤‡å®Œæˆï¼Œæ•°æ®æµå·²å¯åŠ¨")
    }

    func start(fileURL: URL) async throws {
        NSLog("ğŸ¬ å¼€å§‹AppleDeviceå½•åˆ¶: \(fileURL.lastPathComponent)")
        guard isPrepared else { throw RecordingError.notPrepared }
        guard session?.isRunning == true else { throw RecordingError.sessionNotRunning }
        self.startURL = fileURL
        backend.onFirstPTS = { [weak self] time in self?.startTime = time.seconds }
        try await backend.start(fileURL: fileURL)
    }

    func startWithPrepare(deviceId: String, fileURL: URL) async throws {
        try await prepare(deviceId: deviceId)
        try await start(fileURL: fileURL)
    }

    func stop() async throws -> [CRRecorder.BundleInfo.FileAsset] {
        NSLog("ğŸ›‘ åœæ­¢AppleDeviceå½•åˆ¶")
        endTime = CFAbsoluteTimeGetCurrent()
        let url = try await backend.stop()
        if let s = session { AVCaptureSessionHelper.stopRecordingStep2Close(avSession: s) }
        if let url {
            return [CRRecorder.BundleInfo.FileAsset(filename: url.lastPathComponent, tyle: .appleDevice, recordingStartTimestamp: startTime, recordingEndTimestamp: endTime)]
        }
        return []
    }

    func packLastResult() -> [CRRecorder.BundleInfo.FileAsset] {
        if let fileURL = startURL {
            let end = CFAbsoluteTimeGetCurrent()
            let asset = CRRecorder.BundleInfo.FileAsset(filename: fileURL.lastPathComponent, tyle: .appleDevice, recordingStartTimestamp: startTime, recordingEndTimestamp: end)
            return [asset]
        }
        return []
    }
}

class CRMicrophoneRecording {
    var session: AVCaptureSession?
    var delegate: CaptureRecordingDelegate = CaptureRecordingDelegate()
    var startTime: CFAbsoluteTime = 0
    var endTime: CFAbsoluteTime = 0
    var startURL: URL? = nil
    var isPrepared: Bool = false
    var audioLevelHandler: ((Float, Float) -> Void)?
    let queue = DispatchQueue(label: "com.recorderkit.microphone.audio", qos: .userInitiated)

    // æ‰‹åŠ¨åˆ‡æ¢åç«¯ï¼šå¦‚éœ€å›é€€ä¸ºæ–‡ä»¶è¾“å‡ºï¼Œå°†ä¸‹è¡Œæ›¿æ¢ä¸º FileOutputMicBackend()
    private let backend: MicrophoneBackend = AssetWriterMicBackend()
    var processingOptions: MicrophoneProcessingOptions = .init()

    init() {
        print("ğŸ¤ CRMicrophoneRecording åˆå§‹åŒ–")
        delegate.audioLevelHandler = { [unowned self] level, peakLevel in
            audioLevelHandler?(level, peakLevel)
        }
    }

    func prepare(microphoneID: String) async throws {
        print("ğŸ”§ éº¦å…‹é£å½•åˆ¶å‡†å¤‡ä¸­... - è®¾å¤‡ID: \(microphoneID)")

        let device: AVCaptureDevice
        if microphoneID == "default" {
            guard let d = AVCaptureDevice.default(for: .audio) else { throw RecordingError.deviceNotFound }
            device = d
        } else if let specificDevice = AVCaptureDevice(uniqueID: microphoneID) {
            device = specificDevice
        } else {
            guard let d = AVCaptureDevice.default(for: .audio) else { throw RecordingError.deviceNotFound }
            device = d
        }

        let input = try AVCaptureDeviceInput(device: device)
        let session = AVCaptureSession()
        session.beginConfiguration()
        guard session.canAddInput(input) else { throw RecordingError.cannotAddInput }
        session.addInput(input)
        session.commitConfiguration()

        backend.processingOptions = processingOptions
        try backend.configure(session: session, device: device, delegate: delegate, queue: queue)

        session.startRunning()
        guard session.isRunning else { throw RecordingError.sessionFailedToStart }

        self.session = session
        self.isPrepared = true
        print("âœ… éº¦å…‹é£å½•åˆ¶å‡†å¤‡å®Œæˆï¼Œæ•°æ®æµå·²å¯åŠ¨")
    }

    func start(fileURL: URL) async throws {
        print("ğŸ™ï¸ å¼€å§‹éº¦å…‹é£å½•åˆ¶: \(fileURL.lastPathComponent)")
        guard isPrepared else { throw RecordingError.notPrepared }
        guard session?.isRunning == true else { throw RecordingError.sessionNotRunning }

        self.startURL = fileURL
        backend.processingOptions = processingOptions
        backend.onFirstPTS = { [weak self] time in self?.startTime = time.seconds }
        try await backend.start(fileURL: fileURL)
    }

    func startWithPrepare(microphoneID: String, fileURL: URL) async throws {
        try await prepare(microphoneID: microphoneID)
        try await start(fileURL: fileURL)
    }

    func stop() async throws -> [CRRecorder.BundleInfo.FileAsset] {
        print("ğŸ›‘ åœæ­¢éº¦å…‹é£å½•åˆ¶")
        endTime = CFAbsoluteTimeGetCurrent()
        let url = try await backend.stop()
        if let s = session { AVCaptureSessionHelper.stopRecordingStep2Close(avSession: s) }
        if let url {
            return [CRRecorder.BundleInfo.FileAsset(filename: url.lastPathComponent, tyle: .audio, recordingStartTimestamp: startTime, recordingEndTimestamp: endTime)]
        }
        return []
    }

    func packLastResult() -> [CRRecorder.BundleInfo.FileAsset] {
        if let fileURL = startURL {
            let end = CFAbsoluteTimeGetCurrent()
            let asset = CRRecorder.BundleInfo.FileAsset(filename: fileURL.lastPathComponent, tyle: .audio, recordingStartTimestamp: startTime, recordingEndTimestamp: end)
            return [asset]
        }
        return []
    }
}

class AVCaptureSessionHelper {
    
    static func stopRecordingStep1Output(avSession: AVCaptureSession) {
        NSLog("ğŸ›‘ å¼€å§‹åœæ­¢è®¾å¤‡çš„å½•åˆ¶")
        
        // é¦–å…ˆåœæ­¢æ‰€æœ‰å½•åˆ¶è¾“å‡º
        let outputs = avSession.outputs
        for output in outputs {
            if let movieOutput = output as? AVCaptureMovieFileOutput, movieOutput.isRecording {
                NSLog("ğŸ¬ åœæ­¢ç”µå½±æ–‡ä»¶è¾“å‡ºå½•åˆ¶")
                movieOutput.stopRecording()
            } else if let audioOutput = output as? AVCaptureAudioFileOutput, audioOutput.isRecording {
                NSLog("ğŸµ åœæ­¢éŸ³é¢‘æ–‡ä»¶è¾“å‡ºå½•åˆ¶")
                audioOutput.stopRecording()
            }
        }
    }
    static func stopRecordingStep2Close(avSession: AVCaptureSession) {
        let outputs = avSession.outputs

        // ç„¶ååœæ­¢ä¼šè¯
        if avSession.isRunning {
            avSession.stopRunning()
            NSLog("ğŸ“´ ä¼šè¯å·²åœæ­¢è¿è¡Œ")
        }
        
        // ç§»é™¤æ‰€æœ‰è¾“å‡ºï¼ˆå…ˆç§»é™¤è¾“å‡ºï¼‰
        for output in outputs {
            avSession.removeOutput(output)
            NSLog("ğŸ”Œ å·²ç§»é™¤è¾“å‡º: \(type(of: output))")
        }
        
        // ç§»é™¤æ‰€æœ‰è¾“å…¥ï¼ˆåç§»é™¤è¾“å…¥ï¼‰
        let inputs = avSession.inputs
        for input in inputs {
            avSession.removeInput(input)
            NSLog("ğŸ”Œ å·²ç§»é™¤è¾“å…¥: \(type(of: input))")
            
            // å¯¹äºè®¾å¤‡è¾“å…¥ï¼Œç¡®ä¿è®¾å¤‡è¢«æ­£ç¡®é‡Šæ”¾
            if let deviceInput = input as? AVCaptureDeviceInput {
                let device = deviceInput.device
                NSLog("ğŸ¤ é‡Šæ”¾è®¾å¤‡: \(device.localizedName)")
            }
        }
        
        // ä»ä¼šè¯å­—å…¸ä¸­ç§»é™¤
        NSLog("âœ… è®¾å¤‡çš„å½•åˆ¶å·²å®Œå…¨åœæ­¢")
    }
    static func stopRecording(avSession: AVCaptureSession) async throws {
        NSLog("ğŸ›‘ å¼€å§‹åœæ­¢è®¾å¤‡ \(avSession) çš„å½•åˆ¶")
        
        // é¦–å…ˆåœæ­¢æ‰€æœ‰å½•åˆ¶è¾“å‡º
        let outputs = avSession.outputs
        for output in outputs {
            if let movieOutput = output as? AVCaptureMovieFileOutput, movieOutput.isRecording {
                NSLog("ğŸ¬ åœæ­¢ç”µå½±æ–‡ä»¶è¾“å‡ºå½•åˆ¶")
                movieOutput.stopRecording()
            } else if let audioOutput = output as? AVCaptureAudioFileOutput, audioOutput.isRecording {
                NSLog("ğŸµ åœæ­¢éŸ³é¢‘æ–‡ä»¶è¾“å‡ºå½•åˆ¶")
                audioOutput.stopRecording()
            }
        }
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©å½•åˆ¶å®Œæˆ
        try await Task.sleep(nanoseconds: 100_000_000) // 0.1 ç§’
        
        // ç„¶ååœæ­¢ä¼šè¯
        if avSession.isRunning {
            avSession.stopRunning()
            NSLog("ğŸ“´ ä¼šè¯å·²åœæ­¢è¿è¡Œ")
        }
        
        // ç§»é™¤æ‰€æœ‰è¾“å‡ºï¼ˆå…ˆç§»é™¤è¾“å‡ºï¼‰
        for output in outputs {
            avSession.removeOutput(output)
            NSLog("ğŸ”Œ å·²ç§»é™¤è¾“å‡º: \(type(of: output))")
        }
        
        // ç§»é™¤æ‰€æœ‰è¾“å…¥ï¼ˆåç§»é™¤è¾“å…¥ï¼‰
        let inputs = avSession.inputs
        for input in inputs {
            avSession.removeInput(input)
            NSLog("ğŸ”Œ å·²ç§»é™¤è¾“å…¥: \(type(of: input))")
            
            // å¯¹äºè®¾å¤‡è¾“å…¥ï¼Œç¡®ä¿è®¾å¤‡è¢«æ­£ç¡®é‡Šæ”¾
            if let deviceInput = input as? AVCaptureDeviceInput {
                let device = deviceInput.device
                NSLog("ğŸ¤ é‡Šæ”¾è®¾å¤‡: \(device.localizedName)")
            }
        }
        
        // ä»ä¼šè¯å­—å…¸ä¸­ç§»é™¤
        NSLog("âœ… è®¾å¤‡ \(avSession) çš„å½•åˆ¶å·²å®Œå…¨åœæ­¢")
    }
}

extension CRRecorder {
    func recordCamera(cameraId: String, fileURL: URL) async throws -> [CRRecorder.BundleInfo.FileAsset] {
        try await withCheckedThrowingContinuation { continuation in

            let output = AVCaptureMovieFileOutput()
            let input = try! AVCaptureDeviceInput(device: AVCaptureDevice(uniqueID: cameraId)!)
            let session = AVCaptureSession()
            session.beginConfiguration()
            if session.canAddInput(input) {
                session.addInput(input)
            }
            if session.canAddOutput(output) {
                session.addOutput(output)
            }
            session.commitConfiguration()
            
            session.startRunning()
            
            let delegate = CaptureRecordingDelegate()
            var startTime: CFAbsoluteTime = 0
            var endTime: CFAbsoluteTime = 0
            delegate.onStart = { [unowned self] in
                startTime = CFAbsoluteTimeGetCurrent()
            }
            delegate.onError = { [unowned self] error in
                endTime = CFAbsoluteTimeGetCurrent()
                // TODO: maybe has file
                continuation.resume(throwing: error)
                captureDelegates.removeValue(forKey: cameraId)
            }
            delegate.onComplete = { [unowned self] url in
                endTime = CFAbsoluteTimeGetCurrent()
                let duration = endTime - startTime
                let asset = CRRecorder.BundleInfo.FileAsset(filename: url.lastPathComponent, tyle: .webcam)
                continuation.resume(returning: [asset])
                captureDelegates.removeValue(forKey: cameraId)
            }
            
            captureSessions[cameraId] = session
            captureDelegates[cameraId] = delegate
            output.startRecording(to: fileURL, recordingDelegate: delegate)
        }
    }
    
    func recordMicrophone(microphoneID: String, fileURL: URL) async throws -> [CRRecorder.BundleInfo.FileAsset] {
        try await withCheckedThrowingContinuation { continuation in

            let output = AVCaptureAudioFileOutput()
            let device: AVCaptureDevice
            
            // å¤„ç†é»˜è®¤è®¾å¤‡çš„æƒ…å†µ
            if microphoneID == "default" {
                // ä½¿ç”¨ç³»ç»Ÿé»˜è®¤éŸ³é¢‘è¾“å…¥è®¾å¤‡
                device = AVCaptureDevice.default(for: .audio)!
                print("ğŸ™ï¸ ä½¿ç”¨é»˜è®¤éŸ³é¢‘è®¾å¤‡: \(device.localizedName)")
            } else {
                // ä½¿ç”¨æŒ‡å®šçš„è®¾å¤‡ID
                device = AVCaptureDevice(uniqueID: microphoneID)!
            }
            
            let input = try! AVCaptureDeviceInput(device: device)
            let session = AVCaptureSession()
            session.beginConfiguration()
            if session.canAddInput(input) {
                session.addInput(input)
            }
            if session.canAddOutput(output) {
                session.addOutput(output)
            }
            session.commitConfiguration()
            
            session.startRunning()
            
            let delegate = CaptureRecordingDelegate()
            var startTime: CFAbsoluteTime = 0
            var endTime: CFAbsoluteTime = 0
            delegate.onStart = { [unowned self] in
                startTime = CFAbsoluteTimeGetCurrent()
            }
            delegate.onError = { [unowned self] error in
                endTime = CFAbsoluteTimeGetCurrent()
                // TODO: maybe has file
                continuation.resume(throwing: error)
                captureDelegates.removeValue(forKey: microphoneID)
            }
            delegate.onComplete = { [unowned self] url in
                endTime = CFAbsoluteTimeGetCurrent()
                let duration = endTime - startTime
                let asset = CRRecorder.BundleInfo.FileAsset(filename: url.lastPathComponent, tyle: .audio)
                continuation.resume(returning: [asset])
                captureDelegates.removeValue(forKey: microphoneID)
            }
            
            captureSessions[microphoneID] = session
            captureDelegates[microphoneID] = delegate

            output.startRecording(to: fileURL, outputFileType: .m4a, recordingDelegate: delegate)
        }
    }
    
    func stopRecording(deviceID: String) async throws {
        guard let avSession = captureSessions[deviceID] else {
            print("âš ï¸ æœªæ‰¾åˆ°è®¾å¤‡IDä¸º \(deviceID) çš„ä¼šè¯")
            return 
        }
        
        print("ğŸ›‘ å¼€å§‹åœæ­¢è®¾å¤‡ \(deviceID) çš„å½•åˆ¶")
        
        // é¦–å…ˆåœæ­¢æ‰€æœ‰å½•åˆ¶è¾“å‡º
        let outputs = avSession.outputs
        for output in outputs {
            if let movieOutput = output as? AVCaptureMovieFileOutput, movieOutput.isRecording {
                print("ğŸ¬ åœæ­¢ç”µå½±æ–‡ä»¶è¾“å‡ºå½•åˆ¶")
                movieOutput.stopRecording()
            } else if let audioOutput = output as? AVCaptureAudioFileOutput, audioOutput.isRecording {
                print("ğŸµ åœæ­¢éŸ³é¢‘æ–‡ä»¶è¾“å‡ºå½•åˆ¶")
                audioOutput.stopRecording()
            }
        }
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©å½•åˆ¶å®Œæˆ
        try await Task.sleep(nanoseconds: 100_000_000) // 0.1 ç§’
        
        // ç„¶ååœæ­¢ä¼šè¯
        if avSession.isRunning {
            avSession.stopRunning()
            print("ğŸ“´ ä¼šè¯å·²åœæ­¢è¿è¡Œ")
        }
        
        // ç§»é™¤æ‰€æœ‰è¾“å‡ºï¼ˆå…ˆç§»é™¤è¾“å‡ºï¼‰
        for output in outputs {
            avSession.removeOutput(output)
            print("ğŸ”Œ å·²ç§»é™¤è¾“å‡º: \(type(of: output))")
        }
        
        // ç§»é™¤æ‰€æœ‰è¾“å…¥ï¼ˆåç§»é™¤è¾“å…¥ï¼‰
        let inputs = avSession.inputs
        for input in inputs {
            avSession.removeInput(input)
            print("ğŸ”Œ å·²ç§»é™¤è¾“å…¥: \(type(of: input))")
            
            // å¯¹äºè®¾å¤‡è¾“å…¥ï¼Œç¡®ä¿è®¾å¤‡è¢«æ­£ç¡®é‡Šæ”¾
            if let deviceInput = input as? AVCaptureDeviceInput {
                let device = deviceInput.device
                print("ğŸ¤ é‡Šæ”¾è®¾å¤‡: \(device.localizedName)")
            }
        }
        
        // ä»ä¼šè¯å­—å…¸ä¸­ç§»é™¤
        captureSessions.removeValue(forKey: deviceID)
        print("âœ… è®¾å¤‡ \(deviceID) çš„å½•åˆ¶å·²å®Œå…¨åœæ­¢")
    }
}

class CaptureRecordingDelegate: NSObject, AVCaptureFileOutputRecordingDelegate, AVCaptureAudioDataOutputSampleBufferDelegate, AVCaptureVideoDataOutputSampleBufferDelegate {
    var onStart: () -> Void = {}
    var onStartTime: (CMTime) -> Void = {_ in}
    var onError: (Error) -> Void = {_ in}
    var onComplete: (URL) -> Void = { _ in }
    
    private let powerMeter = PowerMeter()
    var audioLevelHandler: ((Float, Float) -> Void)?
    var onAudioSample: ((CMSampleBuffer) -> Void)?
    var onVideoSample: ((CMSampleBuffer) -> Void)?
    var isFirstReceived = false
    var didStartFile = false
    var lastPTS: CMTime = .zero
    
    func fileOutput(_ output: AVCaptureFileOutput, didFinishRecordingTo outputFileURL: URL, from connections: [AVCaptureConnection], error: (any Error)?) {
        if let error = error {
            // æ£€æŸ¥æ˜¯å¦æ˜¯"æˆåŠŸå®Œæˆ"çš„é”™è¯¯ï¼ˆæ¯”å¦‚è¾¾åˆ°æ–‡ä»¶å¤§å°æˆ–æ—¶é—´é™åˆ¶ï¼‰
            if let userInfo = (error as NSError).userInfo[AVErrorRecordingSuccessfullyFinishedKey] as? Bool,
               userInfo == true {
                print("âœ… å½•åˆ¶æ­£å¸¸å®Œæˆï¼ˆè¾¾åˆ°é¢„è®¾é™åˆ¶ï¼‰: \(outputFileURL.path)")
                onComplete(outputFileURL)
            } else {
                NSLog("âš ï¸ [CAPTURE_DELEGATE_ERROR] AVCaptureFileOutput å½•åˆ¶é”™è¯¯: %@", error.localizedDescription)
                print("âŒ å½•åˆ¶é”™è¯¯: \(error.localizedDescription)")
                onError(error)
            }
        } else {
            // æ²¡æœ‰é”™è¯¯ï¼Œå½•åˆ¶æ­£å¸¸å®Œæˆ
            print(" âœ… å½•åˆ¶æ­£å¸¸å®Œæˆ: \(outputFileURL.path)")
            onComplete(outputFileURL)
        }
    }
    
    func fileOutput(_ output: AVCaptureFileOutput, didStartRecordingTo fileURL: URL, from connections: [AVCaptureConnection]) {
        print("ğŸ¬ å¼€å§‹å½•åˆ¶åˆ°: \(fileURL.path)")
        didStartFile = true
        onStart()
    }
    
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        // å°†éŸ³é¢‘æ ·æœ¬ç¼“å†²åŒºè½¬æ¢ä¸ºPCMç¼“å†²åŒºå¹¶å¤„ç†
        if didStartFile && !isFirstReceived {
            isFirstReceived = true
            print("[record-time] å¼€å§‹æ—¶é—´: éº¦å…‹é£data \(CFAbsoluteTimeGetCurrent()) \(sampleBuffer.presentationTimeStamp.seconds)")
            onStartTime(sampleBuffer.presentationTimeStamp)
        }
        lastPTS = sampleBuffer.presentationTimeStamp
        // æ ¹æ®åª’ä½“ç±»å‹åˆ†å‘æ ·æœ¬
        if sampleBuffer.formatDescription?.mediaType == .audio {
            onAudioSample?(sampleBuffer)
            handleAudio(for: sampleBuffer)
        } else if sampleBuffer.formatDescription?.mediaType == .video {
            onVideoSample?(sampleBuffer)
        }
    }
    
    private func handleAudio(for buffer: CMSampleBuffer) {
            let (avg, peak, db) = AudioVolumeCalculator.calculateDetailedVolume(from: buffer)
            let volume = AudioVolumeCalculator.calculateVolume(from: buffer)
            // ç›´æ¥å›è°ƒï¼Œä¸åˆ‡æ¢çº¿ç¨‹
            audioLevelHandler?(volume, peak)
    }
}
